# Music Streaming Analysis Using Spark Structured APIs

## Overview

This project analyzes user music listening behavior using **PySpark Structured APIs**.  
The analysis includes:

- Identifying users’ favorite genres  
- Computing average listening times per user  
- Calculating genre loyalty scores  
- Detecting late-night listeners (12 AM – 5 AM)  

All outputs are captured into a **single text file**.

---

## Dataset Description

1. **Listening Logs (`listening_logs.csv`)** – Generated by `datagen.py`  
    `user_id`    - Unique identifier for each user |
    `song_id`   - Unique identifier for each song |
    `timestamp`    - Date and time when the song was listened |
    `duration_sec` - Duration of the listen in seconds |

2. **Songs Metadata (`Songs_metadata.csv`)** – Generated by `datagen.py`  

   `song_id` - Unique song identifier
   `title`    - Song title
   `artist`  - Artist name
   `genre`   - Music genre
   `mood`    - Mood of the song

---

## Repository Structure

```text
├── datagen.py               # Script to generate input CSV files
├── main.py                  # Spark analysis script
├── listening_logs.csv       # Generated listening logs
├── Songs_metadata.csv       # Generated songs metadata
├── output_file.txt          # Captured output from main.py
└── README.md                # Project documentation
```

---

## Tasks and Outputs

1. **Task 1: User Favorite Genres**  
   - Determines each users most-listened genre.  
   - Output format includes `user_id`, `genre`, and `count`.

2. **Task 2: Average Listen Time**  
   - Computes the average duration of song listens per user.  
   - Output format includes `user_id` and `avg_duration`.

3. **Task 3: Genre Loyalty Scores**  
   - Calculates the number of listens per genre per user.  
   - Ranks users by their top genre loyalty.  
   - Output includes `user_id`, `genre`, `loyalty_score`, and `rank`.

4. **Task 4: Late Night Users (12 AM – 5 AM)**  
   - Identifies users who listen to songs during late-night hours.  
   - Output format includes only `user_id`.

All outputs from the four tasks are saved **together in one text file**: `output_file.txt`.

---

## Execution Instructions

### Prerequisites

Before running the analysis, ensure the following software is installed:

1. **Python 3.x**  
   - Download and Install Python
   - Verify installation:
     ```bash
     python3 --version
     ```

2. **PySpark**  
   - Install via pip:
     ```bash
     pip install pyspark
     ```

---

### Running the Analysis

1. **Generate Input CSVs**  
   Run the data generation script:
   ```bash
   python datagen.py
   ```
   This creates `listening_logs.csv` and `Songs_metadata.csv`.

2. **Run Spark Analysis and Save Output**  
   Execute the main analysis script and redirect output to a file:
   ```powershell
   python main.py > output_file.txt
   ```

3. **Check Results**  
   Open `output_file.txt` to see the combined outputs of all four tasks.

---

## Notes and Common Issues

1. **Missing Python executable warning**:
   - Windows may show:
     ```
     Missing Python executable 'python3'
     ```
   - Safe to ignore if you have Python installed. Optionally, set environment variables:
     ```powershell
     set PYSPARK_PYTHON=C:\Users\chdee\anaconda3\python.exe
     set PYSPARK_DRIVER_PYTHON=C:\Users\chdee\anaconda3\python.exe
     ```

2. **winutils.exe warning**:
   - Appears on Windows, safe to ignore for local Spark execution.

3. **taskkill not recognized**:
   - PowerShell-specific cleanup message, safe to ignore.

